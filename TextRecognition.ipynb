{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kav3deEb4BQ"
   },
   "outputs": [],
   "source": [
    "Cài đặt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JVMhZzacAYt"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets pillow matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEwSKqp3cBEp"
   },
   "source": [
    "Import thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pVaaxmH2cD7W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved to: d:\\My WorkSpace\\Littera\\models\n"
     ]
    }
   ],
   "source": [
    "# Set cache directory to D drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "CACHE_DIR = Path(\"D:/huggingface_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "os.environ['HF_HOME'] = str(CACHE_DIR)\n",
    "os.environ['HF_DATASETS_CACHE'] = str(CACHE_DIR / 'datasets')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cho phép load ảnh bị truncated/incomplete\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Setup model save path\n",
    "BASE_DIR = Path.cwd()  # Thư mục hiện tại của notebook\n",
    "MODEL_SAVE_DIR = BASE_DIR / 'models'\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Models will be saved to: {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKp6n_f0cIpH"
   },
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "b4Pp34GqcMrx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1,000,000 samples from MJSynth dataset...\n",
      "Loaded 1000000 samples successfully!\n",
      "Loaded 1000000 samples successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load 1 triệu mẫu từ dataset (cache sẽ dùng từ D:/huggingface_cache)\n",
    "print(\"Loading 1,000,000 samples from MJSynth dataset...\")\n",
    "ds = load_dataset(\"priyank-m/MJSynth_text_recognition\", split=\"train[:1000000]\")\n",
    "print(f\"Loaded {len(ds)} samples successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra phân bố chữ hoa/thường trong dataset\n",
    "import random\n",
    "sample_labels = [ds[i]['label'] for i in random.sample(range(len(ds)), 100)]\n",
    "\n",
    "uppercase_count = sum(1 for label in sample_labels if any(c.isupper() for c in label))\n",
    "lowercase_count = sum(1 for label in sample_labels if any(c.islower() for c in label))\n",
    "all_upper = sum(1 for label in sample_labels if label.isupper() and label.isalpha())\n",
    "all_lower = sum(1 for label in sample_labels if label.islower() and label.isalpha())\n",
    "mixed_case = sum(1 for label in sample_labels if any(c.isupper() for c in label) and any(c.islower() for c in label))\n",
    "\n",
    "print(f\"Sample của 100 labels:\")\n",
    "print(f\"  Có chữ HOA: {uppercase_count}/100\")\n",
    "print(f\"  Có chữ thường: {lowercase_count}/100\")\n",
    "print(f\"  TOÀN HOA: {all_upper}/100\")\n",
    "print(f\"  toàn thường: {all_lower}/100\")\n",
    "print(f\"  Trộn lẫn: {mixed_case}/100\")\n",
    "print(f\"\\nVí dụ 10 labels đầu:\")\n",
    "for label in sample_labels[:10]:\n",
    "    print(f\"  '{label}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojOMPhZOcPx8"
   },
   "source": [
    "Mã hoá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A_fRnnPtcSfg"
   },
   "outputs": [],
   "source": [
    "# CHARSET phải bao gồm CHỮ HOA + chữ thường + số\n",
    "charset = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "char_to_id = {c: i for i, c in enumerate(charset)}  # nhãn 0..len(charset)-1, blank sẽ là lớp cuối cùng của softmax\n",
    "num_classes = len(charset)  # model Dense sẽ dùng num_classes + 1 (thêm blank)\n",
    "\n",
    "def encode_text(t: str):\n",
    "    # KHÔNG .lower() nữa - giữ nguyên chữ hoa/thường\n",
    "    return [char_to_id[c] for c in t if c in char_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TÙY CHỌN) Data augmentation: cân bằng chữ hoa/thường\n",
    "# Chỉ dùng nếu model sau 20 epochs vẫn output toàn HOA\n",
    "import random\n",
    "\n",
    "def augment_case(text):\n",
    "    \"\"\"Thêm biến thể case để cân bằng dataset\"\"\"\n",
    "    if random.random() < 0.3:  # 30% giữ nguyên\n",
    "        return text\n",
    "    elif random.random() < 0.5:  # 20% chuyển toàn chữ thường\n",
    "        return text.lower()\n",
    "    elif random.random() < 0.7:  # 20% chuyển toàn chữ HOA\n",
    "        return text.upper()\n",
    "    else:  # 30% random case từng ký tự\n",
    "        return ''.join(c.upper() if random.random() > 0.5 else c.lower() for c in text)\n",
    "\n",
    "# Uncomment dòng dưới trong hàm encode_text nếu cần:\n",
    "# t = augment_case(t)  # Thêm vào trước return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vaJPHsJcVQ7"
   },
   "source": [
    "Tham số ảnh và pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tfMU0qkTcW3l"
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 32, 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def gen(examples):\n",
    "    for ex in examples:\n",
    "        try:\n",
    "            img: PIL.Image.Image = ex[\"image\"].convert(\"L\").resize((IMG_WIDTH, IMG_HEIGHT), PIL.Image.BILINEAR)\n",
    "            img = np.array(img, dtype=np.float32) / 255.0\n",
    "            img = img[..., None]  # (H, W, 1)\n",
    "            label_ids = np.array(encode_text(ex[\"label\"]), dtype=np.int32)\n",
    "            \n",
    "            # Bỏ qua nếu label rỗng\n",
    "            if len(label_ids) == 0:\n",
    "                continue\n",
    "                \n",
    "            yield img, label_ids, np.int32(len(label_ids))\n",
    "        except (OSError, PIL.UnidentifiedImageError, Exception) as e:\n",
    "            # Bỏ qua ảnh bị lỗi/hỏng\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmgZ0cGHcZ6H"
   },
   "source": [
    "Trai val/split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oJJL4MnXcbwg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train/validation...\n",
      "Train samples: 900000, Validation samples: 100000\n",
      "Creating TensorFlow datasets...\n",
      "Datasets ready!\n"
     ]
    }
   ],
   "source": [
    "# Split 90% train / 10% validation\n",
    "print(\"Splitting dataset into train/validation...\")\n",
    "split = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_raw, val_raw = split[\"train\"], split[\"test\"]\n",
    "print(f\"Train samples: {len(train_raw)}, Validation samples: {len(val_raw)}\")\n",
    "\n",
    "def make_tfds(hf_dataset):\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, 1), dtype=tf.float32),    # image\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),                          # label (variable length)\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),                               # label_length\n",
    "    )\n",
    "    ds_tf = tf.data.Dataset.from_generator(lambda: gen(hf_dataset), output_signature=output_signature)\n",
    "    ds_tf = ds_tf.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes=(\n",
    "            (IMG_HEIGHT, IMG_WIDTH, 1),   # image\n",
    "            (None,),                      # label padded\n",
    "            (),                           # label_length\n",
    "        ),\n",
    "        padding_values=(\n",
    "            0.0,     # image pad\n",
    "            -1,      # label pad value expected by ctc_label_dense_to_sparse\n",
    "            0,       # label_length\n",
    "        ),\n",
    "        drop_remainder=True\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds_tf\n",
    "\n",
    "print(\"Creating TensorFlow datasets...\")\n",
    "train_ds = make_tfds(train_raw)\n",
    "val_ds = make_tfds(val_raw)\n",
    "print(\"Datasets ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xi0lbpMcffU"
   },
   "source": [
    "Model CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fDDenfjnchjo"
   },
   "outputs": [],
   "source": [
    "def build_crnn(num_classes):\n",
    "    inp = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1), name=\"image\")\n",
    "\n",
    "    x = keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)               # 16x64\n",
    "    x = keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)               # 8x32\n",
    "    x = keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 1))(x)               # 4x32\n",
    "    x = keras.layers.Conv2D(512, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 1))(x)               # 2x32\n",
    "    x = keras.layers.Conv2D(512, 2, padding=\"valid\", activation=\"relu\")(x)  # 1x31\n",
    "\n",
    "    # Reshape -> time steps x features (timesteps = 31)\n",
    "    x = keras.layers.Reshape(target_shape=(31, 512))(x)\n",
    "\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "    # +1 cho blank\n",
    "    out = keras.layers.Dense(num_classes + 1, activation=\"softmax\")(x)  # (B, T, C+1)\n",
    "    return keras.Model(inp, out, name=\"crnn\")\n",
    "\n",
    "base_model = build_crnn(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei7MkWL9cjWP"
   },
   "source": [
    "Train model với CTC loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-s3dgY74clSl"
   },
   "outputs": [],
   "source": [
    "labels = keras.Input(shape=(None,), dtype=tf.int32, name=\"labels\")\n",
    "input_length = keras.Input(shape=(1,), dtype=tf.int32, name=\"input_length\")\n",
    "label_length = keras.Input(shape=(1,), dtype=tf.int32, name=\"label_length\")\n",
    "\n",
    "logits = base_model.output  # (B, T, C+1)\n",
    "def ctc_loss_layer(args):\n",
    "    y_true, y_pred, in_len, lab_len = args\n",
    "    return keras.backend.ctc_batch_cost(y_true, y_pred, in_len, lab_len)\n",
    "\n",
    "loss_out = keras.layers.Lambda(ctc_loss_layer, name=\"ctc_loss\")([labels, logits, input_length, label_length])\n",
    "\n",
    "train_model = keras.Model(\n",
    "    inputs=[base_model.input, labels, input_length, label_length],\n",
    "    outputs=loss_out,\n",
    ")\n",
    "\n",
    "train_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=lambda y_true, y_pred: y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHQVwhCXcrNW"
   },
   "source": [
    "Pack batch: thêm input_length (timesteps = 31) và dummy y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DFxvTRA4crmq"
   },
   "outputs": [],
   "source": [
    "TIMESTEPS = 31\n",
    "\n",
    "def pack_batch(images, labels_batch, label_lens):\n",
    "    bsz = tf.shape(images)[0]\n",
    "    in_len = tf.fill([bsz, 1], TIMESTEPS)\n",
    "    lab_len = tf.expand_dims(label_lens, axis=1)\n",
    "    inputs = {\n",
    "        \"image\": images,\n",
    "        \"labels\": labels_batch,\n",
    "        \"input_length\": in_len,\n",
    "        \"label_length\": lab_len,\n",
    "    }\n",
    "    # y dummy (Keras cần target, nhưng loss đã ở outputs)\n",
    "    y = tf.zeros((bsz, 1), dtype=tf.float32)\n",
    "    return inputs, y\n",
    "\n",
    "train_data = train_ds.map(pack_batch)\n",
    "val_data = val_ds.map(pack_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juY6XwEGcuaU"
   },
   "source": [
    " Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on 1,000,000 samples...\n",
      "Checkpoint will be saved to: d:\\My WorkSpace\\Littera\\models\\crnn_ocr_ctc_1m_checkpoint.h5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    110/Unknown \u001b[1m61s\u001b[0m 557ms/step - loss: 1.5860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training on 1,000,000 samples...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint will be saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Tăng epochs cho dataset lớn\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     36\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Lưu model cuối cùng\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSaving final model to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My WorkSpace\\Littera\\littera_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "checkpoint_path = MODEL_SAVE_DIR / \"crnn_ocr_ctc_1m_checkpoint.h5\"\n",
    "final_model_path = MODEL_SAVE_DIR / \"crnn_ocr_ctc_1m.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_path),\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Starting training on 1,000,000 samples...\")\n",
    "print(f\"Checkpoint will be saved to: {checkpoint_path}\")\n",
    "\n",
    "history = train_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=20,  # Tăng epochs cho dataset lớn\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    " \n",
    "# Lưu model cuối cùng\n",
    "print(f\"\\nSaving final model to: {final_model_path}\")\n",
    "base_model.save(str(final_model_path))\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume Training từ Checkpoint (Nếu cần)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: d:\\My WorkSpace\\Littera\\models\\crnn_ocr_ctc_1m_checkpoint.h5\n",
      "✓ Loaded model from checkpoint\n",
      "Error loading checkpoint: 'Dense' object has no attribute 'output_shape'\n",
      "✓ Loaded model from checkpoint\n",
      "Error loading checkpoint: 'Dense' object has no attribute 'output_shape'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Tìm output của base model (trước Lambda layer)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, keras.layers.Dense) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_shape\u001b[49m[-\u001b[32m1\u001b[39m] == \u001b[32m63\u001b[39m:  \u001b[38;5;66;03m# 62 chars + blank\u001b[39;00m\n\u001b[32m     36\u001b[39m         base_output = layer.output\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Dense' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "# CHỈ DÙNG NẾU TRAINING BỊ DỪNG/CRASH\n",
    "# Cell này load checkpoint và tiếp tục train\n",
    "\n",
    "checkpoint_path = MODEL_SAVE_DIR / \"crnn_ocr_ctc_1m_checkpoint.h5\"\n",
    "\n",
    "print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "# Định nghĩa ctc_loss_layer\n",
    "def ctc_loss_layer(args):\n",
    "    y_true, y_pred, in_len, lab_len = args\n",
    "    return keras.backend.ctc_batch_cost(y_true, y_pred, in_len, lab_len)\n",
    "\n",
    "# Load checkpoint\n",
    "loaded_model = keras.models.load_model(\n",
    "    str(checkpoint_path),\n",
    "    custom_objects={'ctc_loss_layer': ctc_loss_layer},\n",
    "    compile=False\n",
    ")\n",
    "print(\"✓ Loaded model from checkpoint\")\n",
    "\n",
    "# Kiểm tra xem là base_model hay train_model\n",
    "if len(loaded_model.inputs) == 1:\n",
    "    # Chỉ có 1 input 'image' → đây là base_model\n",
    "    base_model = loaded_model\n",
    "    print(\"✓ Checkpoint is base_model\")\n",
    "else:\n",
    "    # Nhiều inputs → đây là train_model, cần extract base_model\n",
    "    print(\"✓ Extracting base_model from train_model...\")\n",
    "    \n",
    "    # Tìm input 'image'\n",
    "    image_input = None\n",
    "    for inp in loaded_model.inputs:\n",
    "        if 'image' in inp.name:\n",
    "            image_input = inp\n",
    "            break\n",
    "    \n",
    "    # Tìm Dense layer cuối cùng (output layer của base model)\n",
    "    base_output = None\n",
    "    for layer in reversed(loaded_model.layers):  # Duyệt ngược từ cuối\n",
    "        if isinstance(layer, keras.layers.Dense):\n",
    "            # Kiểm tra output shape\n",
    "            try:\n",
    "                shape = layer.output.shape  # Dùng layer.output.shape, KHÔNG phải layer.output_shape\n",
    "                if shape[-1] == (num_classes + 1):  # 63 = 62 chars + 1 blank\n",
    "                    base_output = layer.output\n",
    "                    print(f\"   Found Dense layer: {layer.name} with output shape {shape}\")\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if base_output is None:\n",
    "        raise ValueError(\"Could not find Dense output layer in checkpoint!\")\n",
    "    \n",
    "    base_model = keras.Model(inputs=image_input, outputs=base_output)\n",
    "    print(\"✓ Extracted base_model successfully\")\n",
    "\n",
    "# Rebuild train_model\n",
    "labels = keras.Input(shape=(None,), dtype=tf.int32, name=\"labels\")\n",
    "input_length = keras.Input(shape=(1,), dtype=tf.int32, name=\"input_length\")\n",
    "label_length = keras.Input(shape=(1,), dtype=tf.int32, name=\"label_length\")\n",
    "\n",
    "logits = base_model.output\n",
    "\n",
    "# Lambda layer với output_shape\n",
    "loss_out = keras.layers.Lambda(\n",
    "    ctc_loss_layer, \n",
    "    output_shape=(1,),\n",
    "    name=\"ctc_loss\"\n",
    ")([labels, logits, input_length, label_length])\n",
    "\n",
    "train_model = keras.Model(\n",
    "    inputs=[base_model.input, labels, input_length, label_length],\n",
    "    outputs=loss_out,\n",
    ")\n",
    "\n",
    "# Compile với LR thấp hơn\n",
    "train_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-4),\n",
    "    loss=lambda y_true, y_pred: y_pred\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model ready to resume training!\")\n",
    "print(f\"   Base model output shape: {base_model.output.shape}\")\n",
    "print(f\"   Will train remaining epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training với callbacks\n",
    "final_model_path = MODEL_SAVE_DIR / \"crnn_ocr_ctc_1m.h5\"\n",
    "\n",
    "callbacks_resume = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_path),\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Resuming training...\")\n",
    "print(f\"Training will continue for remaining epochs (7-20)\")\n",
    "\n",
    "# Chạy tiếp 14 epochs (20 - 6)\n",
    "history_resume = train_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=14,  # 20 - 6 = 14 epochs còn lại\n",
    "    callbacks=callbacks_resume,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Lưu model cuối cùng\n",
    "print(f\"\\nSaving final model to: {final_model_path}\")\n",
    "base_model.save(str(final_model_path))\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uqBD3DdTcxIt"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot training & validation loss\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Training History')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(str(MODEL_SAVE_DIR / 'training_history.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(f\"Final model saved at: {final_model_path}\")\n",
    "print(f\"Model size: {final_model_path.stat().st_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAKys-Uhc7pB"
   },
   "source": [
    "Xem vài mẫu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHFGxS7Fc8e8"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(val_ds))\n",
    "imgs, lab_ids, lab_lens = batch\n",
    "preds = base_model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPkQnMJEc_iS"
   },
   "outputs": [],
   "source": [
    "# Greedy decode\n",
    "input_len_np = np.full((preds.shape[0],), TIMESTEPS)\n",
    "results = keras.backend.ctc_decode(preds, input_length=input_len_np, greedy=True)[0][0].numpy()\n",
    "\n",
    "# Tạo lại id_to_char từ charset đã cập nhật (có chữ HOA)\n",
    "id_to_char = {i: c for i, c in enumerate(charset)}\n",
    "\n",
    "def decode_ids(ids):\n",
    "    return \"\".join(id_to_char[i] for i in ids if i != -1)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(imgs[i,...,0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"pred: {decode_ids(results[i])}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "littera_env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
